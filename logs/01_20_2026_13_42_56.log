{"available_keys": ["GOOGLE_API_KEY", "GROQ_API_KEY"], "timestamp": "2026-01-20T18:42:58.549608Z", "level": "info", "event": "Environment variables validated"}
{"config_keys": ["faiss_db", "embedding_model", "retriever", "llm"], "timestamp": "2026-01-20T18:42:58.566169Z", "level": "info", "event": "Configuration loaded successfully"}
{"timestamp": "2026-01-20T18:42:58.566169Z", "level": "info", "event": "Loading embedding model..."}
Loading faiss with AVX512 support.
Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
Loading faiss with AVX2 support.
Successfully loaded faiss with AVX2 support.
{"available_keys": ["GOOGLE_API_KEY", "GROQ_API_KEY"], "timestamp": "2026-01-20T18:42:58.688891Z", "level": "info", "event": "Environment variables validated"}
{"config_keys": ["faiss_db", "embedding_model", "retriever", "llm"], "timestamp": "2026-01-20T18:42:58.690966Z", "level": "info", "event": "Configuration loaded successfully"}
{"timestamp": "2026-01-20T18:42:58.691949Z", "level": "info", "event": "Loading embedding model..."}
{"timestamp": "2026-01-20T18:42:58.724173Z", "level": "info", "event": "Loading LLM..."}
{"provider": "google", "model": "gemini-2.0-flash", "temperature": 0, "max_tokens": 2048, "timestamp": "2026-01-20T18:42:58.724173Z", "level": "info", "event": "Loading LLM"}
{"class_name": "ChatGoogleGenerativeAI", "timestamp": "2026-01-20T18:42:58.750869Z", "level": "info", "event": "LLM loaded successfully"}
{"session_id": "test_conversational_rag", "timestamp": "2026-01-20T18:42:58.750869Z", "level": "info", "event": "Created history-aware retriever"}
{"session_id": "test_conversational_rag", "timestamp": "2026-01-20T18:42:58.757708Z", "level": "info", "event": "Created RAG chain"}
{"session_id": "test_conversational_rag", "timestamp": "2026-01-20T18:42:58.757946Z", "level": "info", "event": "Wrapped chain with message history"}
{"session_id": "test_conversational_rag", "timestamp": "2026-01-20T18:42:58.758463Z", "level": "info", "event": "New chat session history created"}
HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
AFC is enabled with max remote calls: 10.
HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
{"session_id": "test_conversational_rag", "count": 5, "top_sources": ["data\\single_document_chat\\session_20260120_161538_7923f003.pdf", "data\\single_document_chat\\session_20260120_161538_7923f003.pdf", "data\\single_document_chat\\session_20260120_161538_7923f003.pdf"], "top_pages": [2, 1, 1], "timestamp": "2026-01-20T18:43:00.337998Z", "level": "info", "event": "Retrieved docs"}
{"session_id": "test_conversational_rag", "user_input": "What is the significance of the attention mechanism? can you explain it in simple terms?", "answer_preview": "The attention mechanism lets a model focus on the most relevant parts of the input when processing information. Instead of treating all input elements", "timestamp": "2026-01-20T18:43:00.337998Z", "level": "info", "event": "Chain invoked successfully"}
